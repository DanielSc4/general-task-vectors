{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/document/general-task-vectors/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'gpt2'\n",
    "# MODEL_NAME = 'microsoft/phi-2'\n",
    "# MODEL_NAME = 'EleutherAI/pythia-1B'\n",
    "# MODEL_NAME = 'stabilityai/stablelm-2-zephyr-1_6b'\n",
    "\n",
    "LOAD_IN_8BIT = False\n",
    "RELATIVE_PATH = '../'\n",
    "\n",
    "dataset_name = 'country-capital'\n",
    "# select number of ICL examples (query excluded)\n",
    "ICL_examples = 3\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset len: 50\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_json_dataset(json_path):\n",
    "    with open(json_path, encoding='utf-8') as file:\n",
    "        dataset = json.load(file)\n",
    "    return dataset\n",
    "\n",
    "dataset = load_json_dataset(f'{RELATIVE_PATH}data/{dataset_name}.json')\n",
    "dataset = list(map(lambda x: tuple(x.values()), dataset))\n",
    "\n",
    "if debug:\n",
    "    dataset = dataset[0:50]\n",
    "\n",
    "print(f'dataset len: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from src.utils.model_utils import load_gpt_model_and_tokenizer, set_seed\n",
    "from src.extraction import get_mean_activations\n",
    "from src.utils.prompt_helper import tokenize_ICL\n",
    "from src.intervention import compute_indirect_effect\n",
    "set_seed(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer, config, device = load_gpt_model_and_tokenizer(MODEL_NAME, LOAD_IN_8BIT)\n",
    "tok_ret, ids_ret, correct_labels = tokenize_ICL(tokenizer, ICL_examples = ICL_examples, dataset = dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get activations and measure head's importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[x] Extracting activations:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[x] Extracting activations (layer: 11/12): 100%|██████████| 12/12 [00:07<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[x] Model accuracy: 0.17, using 2 (out of 12) examples to compute mean activations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 12, 31, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "if os.path.isfile(\n",
    "    f'{RELATIVE_PATH}output/{dataset_name}_mean_activations_{MODEL_NAME.replace(\"/\", \"-\")}_ICL{ICL_examples}.pt'\n",
    "):\n",
    "    mean_activations = torch.load(f'{RELATIVE_PATH}output/{dataset_name}_mean_activations_{MODEL_NAME.replace(\"/\", \"-\")}_ICL{ICL_examples}.pt')\n",
    "    mean_activations = mean_activations.to(device)\n",
    "else:\n",
    "    mean_activations = get_mean_activations(\n",
    "        tokenized_prompts=tok_ret,\n",
    "        important_ids=ids_ret,\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        config=config,\n",
    "        correct_labels=correct_labels,\n",
    "        device='cuda',\n",
    "    )\n",
    "mean_activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing edited model (l: 4/12, h: 4/12):   0%|          | 0/3 [00:16<?, ?it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cie, probs_original, probs_edited  \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_indirect_effect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmean_activations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_activations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mICL_examples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mICL_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/document/general-task-vectors/notebooks/../src/intervention.py:133\u001b[0m, in \u001b[0;36mcompute_indirect_effect\u001b[0;34m(model, tokenizer, config, dataset, mean_activations, ICL_examples, batch_size)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m head_j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_heads\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m    130\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mset_description(\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing edited model (l: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_i\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, h: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhead_j\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    132\u001b[0m         )\n\u001b[0;32m--> 133\u001b[0m         returned \u001b[38;5;241m=\u001b[39m \u001b[43mreplace_heads_w_avg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenized_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_batch_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimportant_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_batch_important_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayers_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_j\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m            \u001b[49m\u001b[43mavg_activations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmean_activations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_j\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m         edited[:, layer_i, head_j, :] \u001b[38;5;241m=\u001b[39m returned\n\u001b[1;32m    142\u001b[0m probs_edited\u001b[38;5;241m.\u001b[39mappend(edited\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[0;32m~/document/general-task-vectors/notebooks/../src/intervention.py:37\u001b[0m, in \u001b[0;36mreplace_heads_w_avg\u001b[0;34m(tokenized_prompt, important_ids, layers_heads, avg_activations, model, config)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layers_heads) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(avg_activations), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayers_heads and avg_activations must have the same length. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(layers_heads)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(avg_activations)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     35\u001b[0m d_head \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md_model\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_heads\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m model\u001b[38;5;241m.\u001b[39minvoke(tokenized_prompt) \u001b[38;5;28;01mas\u001b[39;00m invoker:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (num_layer, num_head) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(layers_heads):\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;66;03m# select the head (output shape is torch.Size([batch, seq_len, d_model]))\u001b[39;00m\n\u001b[1;32m     40\u001b[0m         \n\u001b[1;32m     41\u001b[0m         \u001b[38;5;66;03m# https://github.com/huggingface/transformers/blob/224ab70969d1ac6c549f0beb3a8a71e2222e50f7/src/transformers/models/gpt2/modeling_gpt2.py#L341\u001b[39;00m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;66;03m# shape: tuple[output from the attention module (hidden state), present values (cache), attn_weights] \u001b[39;00m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;66;03m# (taking 0-th value)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m         attention_head_values \u001b[38;5;241m=\u001b[39m rgetattr(model, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattn_hook_names\u001b[39m\u001b[38;5;124m'\u001b[39m][num_layer])\u001b[38;5;241m.\u001b[39moutput[\u001b[38;5;241m0\u001b[39m][\n\u001b[1;32m     45\u001b[0m             :, :, (num_head \u001b[38;5;241m*\u001b[39m d_head) : ((num_head \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m d_head)\n\u001b[1;32m     46\u001b[0m         ]\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/nnsight/contexts/DirectInvoker.py:27\u001b[0m, in \u001b[0;36mDirectInvoker.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DirectInvoker:\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mInvoker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__enter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/nnsight/contexts/Invoker.py:62\u001b[0m, in \u001b[0;36mInvoker.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_prepare_inputs(\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan:\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scan\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmeta_model\u001b[38;5;241m.\u001b[39mnamed_modules():\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/nnsight/models/NNsightModel.py:386\u001b[0m, in \u001b[0;36mNNsightModel._scan\u001b[0;34m(self, prepared_inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03mAbstract method to directly call the meta_model and therefore populate the input/output shapes etc. To be implemented by inheritors.\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m    prepared_inputs (Any): Prepared inputs.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m accelerate\u001b[38;5;241m.\u001b[39minit_empty_weights(include_buffers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepared_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/nnsight/module.py:100\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m     96\u001b[0m     module_proxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mmodule_proxy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_path)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m module_proxy\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1074\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1074\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/nnsight/module.py:100\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m     96\u001b[0m     module_proxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mmodule_proxy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_path)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m module_proxy\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:888\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    876\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    877\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    878\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    885\u001b[0m         output_attentions,\n\u001b[1;32m    886\u001b[0m     )\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/nnsight/module.py:100\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m     96\u001b[0m     module_proxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mmodule_proxy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_path)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m module_proxy\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:390\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    388\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    389\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 390\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    399\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/nnsight/module.py:100\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m     96\u001b[0m     module_proxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mmodule_proxy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_path)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m module_proxy\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:312\u001b[0m, in \u001b[0;36mGPT2Attention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    310\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m encoder_attention_mask\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m     query, key, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_size, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    314\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_heads(query, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    315\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_heads(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/nnsight/module.py:100\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m     96\u001b[0m     module_proxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mmodule_proxy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_path)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m module_proxy\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/transformers/pytorch_utils.py:102\u001b[0m, in \u001b[0;36mConv1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    101\u001b[0m     size_out \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnf,)\n\u001b[0;32m--> 102\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddmm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(size_out)\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/utils/_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/_prims_common/wrappers.py:229\u001b[0m, in \u001b[0;36mout_wrapper.<locals>._out_wrapper.<locals>._fn\u001b[0;34m(out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    227\u001b[0m             kwargs[k] \u001b[38;5;241m=\u001b[39m out_attr\n\u001b[0;32m--> 229\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(result, TensorLike)\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_tensor\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Tuple)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(out_names)\n\u001b[1;32m    235\u001b[0m )\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# Naively you might expect this assert to be true, but\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# it's not:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# be a normal meta tensor, but this is perfectly\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# harmless.\u001b[39;00m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/_decomp/decompositions.py:70\u001b[0m, in \u001b[0;36mtype_casts.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 70\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mincrease_prec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mincrease_prec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute_dtype_only:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/_decomp/decompositions.py:1239\u001b[0m, in \u001b[0;36maddmm\u001b[0;34m(self, mat1, mat2, beta, alpha)\u001b[0m\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;66;03m# The output of aten.addmm is contiguous, we need to match this behavior in the decomposition.\u001b[39;00m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;66;03m# The original implementation 'beta * self + out' would return a strided tensor if `self` is strided.\u001b[39;00m\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;66;03m# We thus use `out`, the output of torch.mm, which is always contiguous, as the first argument for addition.\u001b[39;00m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# This is relying on TensorIterator's behavior that it takes higher precedence on the stride of first input.\u001b[39;00m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;66;03m# Alternative, we can write `(beta * self + out).contiguous()`, but it introduces another copy in some cases.\u001b[39;00m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# This implementation is not ideal, and we should revisit this when we have a better solution.\u001b[39;00m\n\u001b[0;32m-> 1239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/_prims_common/wrappers.py:229\u001b[0m, in \u001b[0;36mout_wrapper.<locals>._out_wrapper.<locals>._fn\u001b[0;34m(out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    227\u001b[0m             kwargs[k] \u001b[38;5;241m=\u001b[39m out_attr\n\u001b[0;32m--> 229\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(result, TensorLike)\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_tensor\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Tuple)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(out_names)\n\u001b[1;32m    235\u001b[0m )\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# Naively you might expect this assert to be true, but\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# it's not:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# be a normal meta tensor, but this is perfectly\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# harmless.\u001b[39;00m\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/_prims_common/wrappers.py:120\u001b[0m, in \u001b[0;36melementwise_type_promotion_wrapper.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m type_promoting_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    114\u001b[0m     bound\u001b[38;5;241m.\u001b[39marguments[x]\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_promoting_arg_names  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    117\u001b[0m )\n\u001b[1;32m    119\u001b[0m flattened_type_promoting_args \u001b[38;5;241m=\u001b[39m tree_flatten(type_promoting_args)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 120\u001b[0m compute_dtype, result_dtype \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melementwise_dtypes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflattened_type_promoting_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_promotion_kind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_promotion_kind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m promoted_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    126\u001b[0m     x: _maybe_convert_to_dtype(bound\u001b[38;5;241m.\u001b[39marguments[x], compute_dtype)\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_promoting_arg_names  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    129\u001b[0m }\n\u001b[1;32m    130\u001b[0m bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mupdate(promoted_args)\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/_prims_common/__init__.py:1326\u001b[0m, in \u001b[0;36melementwise_dtypes\u001b[0;34m(type_promotion_kind, *_args)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melementwise_dtypes\u001b[39m(\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;241m*\u001b[39m_args,\n\u001b[1;32m   1238\u001b[0m     type_promotion_kind: ELEMENTWISE_TYPE_PROMOTION_KIND,\n\u001b[1;32m   1239\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mdtype, torch\u001b[38;5;241m.\u001b[39mdtype]:\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;124;03m    Computes the computation and result dtypes for elementwise type promotion\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;124;03m    on the given arguments and with the given elementwise type promotion kind.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1323\u001b[0m \n\u001b[1;32m   1324\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1328\u001b[0m     highest_type: \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args:\n",
      "File \u001b[0;32m~/document/general-task-vectors/.venv/lib/python3.10/site-packages/torch/_prims_common/__init__.py:1326\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melementwise_dtypes\u001b[39m(\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;241m*\u001b[39m_args,\n\u001b[1;32m   1238\u001b[0m     type_promotion_kind: ELEMENTWISE_TYPE_PROMOTION_KIND,\n\u001b[1;32m   1239\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mdtype, torch\u001b[38;5;241m.\u001b[39mdtype]:\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;124;03m    Computes the computation and result dtypes for elementwise type promotion\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;124;03m    on the given arguments and with the given elementwise type promotion kind.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1323\u001b[0m \n\u001b[1;32m   1324\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m _args \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1328\u001b[0m     highest_type: \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cie, probs_original, probs_edited  = compute_indirect_effect(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    config=config,\n",
    "    dataset=dataset, \n",
    "    mean_activations=mean_activations,\n",
    "    ICL_examples = ICL_examples,\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "cie = torch.load(f'{RELATIVE_PATH}output/sentiment_cie_microsoft-phi-2.pt')\n",
    "\n",
    "ax = sns.heatmap(cie.mean(dim=0), linewidth=0.5, cmap='RdBu')\n",
    "plt.title('phi-2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
